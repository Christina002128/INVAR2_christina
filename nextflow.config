params {
    /*
     * Essential variables.
     */

    STUDY_ID = "PARADIGM"

    // unique identifier for CONNOR setting; f = consensus threshold, s = family size
    ERROR_SUPPRESSION_NAME = "f0.9_s2"

    LAYOUT_TABLE="${launchDir}/bed/combined.SLX_table_with_controls_031220.csv"

    TUMOUR_MUTATIONS_CSV="${launchDir}/bed/PARADIGM_mutation_list_full_cohort_hg19.csv"

    // Think this is not needed. For PARADIGM at least, it's derived from TUMOUR_MUTATIONS_CSV
    // [bed/example.bed] BED file of patient-specific loci
    // BED = "${launchDir}/bed/PARADIGM_mutation_list_full_cohort_hg19.bed"

    // [40]   min MAPQ threshold
    MAPQ = 40

    // [20] min BASEQ threshold
    BASEQ = 20

    // [./to_run.txt] this is a txt file containing the bam IDs to be run. Ensure that all files are in the same folder
    INPUT_FILES = "${launchDir}/to_run.txt"

    // choose between Rubicon and Agilent -- needed for drawing out barcode information
    LIBRARY_PREP="Aglient"


    /*
     * Optional variables
     * Please check over the variables below [non-essential, can use defaults]
     */

    // [5] split mpileup output into N files. if you have few files then set this higher
    CHUNKS=5

    // [output] output folder.
    OUT="output"

    // [output_size] - output folder for size annotation files
    OUTPUT_SIZE_FOLDER="output_size"

    // [5] min DP to consider for mpileup. Set to 1 for sWGS samples.
    MIN_DP=2

    // [10] set how many bases either side of the target base to assess for background error rate.
    SLOP_BP=10

    // [0.25] smoothing function for size profile - width of smoothing
    SMOOTH=0.25

    // MAX DP for mpileup. MAX DP is also set in config2 when parsing TSV files.
    MAX_DP=100000

    // Whether to remove duplicates in pile ups.
    REMOVE_DUPLICATES = true

    /*
     * Reference files
     */

    RESOURCES_DIR = "${launchDir}/invar_reference"

    FASTAREF="${RESOURCES_DIR}/ucsc.hg19.fasta"

    HG19_GENOME="${RESOURCES_DIR}/hg19.genome"

    // 1000 genomes SNP database
    K1G_DB="${RESOURCES_DIR}/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz"

    // cosmic database
    COSMIC_DB="${RESOURCES_DIR}/CosmicCodingMuts.vcf.gz"

    /*
     * Final file names.
     */

    FINAL_PREFIX="${STUDY_ID}.${ERROR_SUPPRESSION_NAME}.BQ_${BASEQ}.MQ_${MAPQ}"

    /*
     * Settings that come from config2.R
     */

    /*
     * Filtering INVAR loci
     */

    // Omit data points with uncharacteristially high unique depth given the input mass used
    max_depth = 1500

    // Minimum depth is set by mpileups as 5, here we require at least 5 ref reads at a locus, set to 0 for sWGS
    min_ref_depth = 5

    // Excludes data points due to poor MQ and SB, but locus is retained
    individual_MQSB_threshold = 0.01

    // Blacklist loci with >= N separate alternate alleles.
    n_alt_alleles_threshold = 3

    // Blacklist multiallelic loci with a mutant read count of >= N in the minor mutant allele.
    minor_alt_allele_threshold = 2

    // Loci with >0 entries in COSMIC are considered as COSMIC mutations
    cosmic_threshold = 0

    /*
     * Off target calculations.
     */

    // Blacklist loci that have signal in >30% of the nonptspec samples
    proportion_of_controls = 0.1

    // Filter loci with a background allele frequency in controls greater than this value
    max_background_mean_allele_frequency = 0.01
    
    // Maximum allele frequency value for acceptable samples.
    allele_frequency_threshold = 0.01

    // Only change to true if you are running blood spot data through the pipeline.
    // This omits outlier-suppression on samples with deduplicated depth of <5x because
    // high AF loci cannot be reliably identified with low depth
    is_bloodspot = false
}



manifest {
    mainScript = 'invar.nf'
    nextflowVersion = '>=20.0.0'
    version = '2.0.0'
}

executor {
    $slurm {
        queueSize = 150
        pollInterval = '30sec'
        queue = 'general'
        clusterOptions = "--nodes=1 --open-mode=truncate"
    }
}

singularity.enabled = true
singularity.autoMounts = true
singularity.runOptions = "-B '${projectDir}' -B '${params.RESOURCES_DIR}'"

process {
    // container = "crukcibioinformatics/alignment:40"
    // container = "/home/bowers01/work/invar/rewrite/container/invar_sandbox"
    container = "${projectDir}/container/invar.sif"

    errorStrategy = {
        task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish'
    }
}

profiles {
    standard {
        process.executor = 'local'
        executor.$local.cpus = 6
        executor.$local.memory = 20.GB
    }

    cluster {
        process.executor = 'slurm'
    }

    bioinf {
        params.RESOURCES_DIR = "/ssd/personal/bowers01/invar_references"
        process.executor = 'local'
        executor.$local.cpus = 28
        executor.$local.memory = 180.GB
    }
}

